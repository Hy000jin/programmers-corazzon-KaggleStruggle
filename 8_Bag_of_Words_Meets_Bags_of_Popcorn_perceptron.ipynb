{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로그래머스 강의\n",
    "github - [corazzon-github](https://github.com/corazzon/KaggleStruggle/blob/master/word2vec-nlp-tutorial/MLWave-online-learning-perceptron.ipynb)\n",
    "\n",
    "원문 출처 : https://mlwave.com/online-learning-perceptron/\n",
    "\n",
    "소스코드 출처\n",
    "\n",
    "* https://github.com/MLWave/online-learning-perceptron\n",
    "* https://github.com/MLWave/online-learning-perceptron/blob/master/perceptron.py\n",
    "* 위 소스코드를 Python3에서 실행되도록 일부 수정하였다.\n",
    "온라인 학습 퍼셉트론\n",
    "\n",
    "* 퍼셉트론 : 가장 단순한 인공신경망이다. 이 글은 1943년에 고안된 개념에서 2015년 Kaggle 경진대회(영화 리뷰가 긍정인지 부정인지 예측)로 옮겨간다. NLP 감정 분석 작업에서 하나의 인공 신경 세포가 0.95 AUC를 얻을 수 있음을 보여준다.\n",
    "\n",
    "\n",
    "## NLP with Perceptron\n",
    "* McCulloch \"신경 활동에 'all-or-nothing'\" 활동이 있다고 추론\n",
    "* 활성화 임계값에 도달하면 return 1\n",
    "* 아니며 return 0\n",
    "* McCulloch-Pitts 논문\n",
    "\n",
    "example<br>\n",
    "*\"a Logical Calculus of the Ideas Immanent in Nervous Activity”(신경 행동에서 내재적 사고의 논리적 계산)\"*<br>\n",
    "새가 씨앗과 같이 작은 물체를 먹으려고 한다. 이 행동을 표로 나타내보자\n",
    "![steemit](https://steemitimages.com/640x0/https://cdn.steemitimages.com/DQmPd56VKBmht266CpBn6gUUFrQhDstJPhfJaZRSEVZGRmE/noname01.png \"Social Behavior Analytics\")\n",
    "\n",
    "```\n",
    "1. 둘다 1이어야 1을 출력하는 것은 END 연산가 똑같다.\n",
    "2. 활성화 임계값을 1.5로 설정했다고 했을 때\n",
    "3. Brown과 Round가 모두 충족되었을 때만, 임계치인 1.5보다 크므로 입력값이 1이 된다. \n",
    "4. 그 외는 0으로 출력되게 된다.\n",
    "```\n",
    "\n",
    "### 퍼셉트론\n",
    "퍼셉트로이 동작하는 방식은 각 노드의 가중치와 입력치를 곱한 것을 모두 합한 값이 활성화함수에 의해 판단되는데, 그 값이 임계치(보통0)보다 크면 뉴런이 활성화되고 결과값으로 1을 출력한다. 뉴런이 활성화되지 않으면 결과값으로 -1을 출력한다.\n",
    "\n",
    "다층 퍼셉트론으로 XOR연산도 가능하다.\n",
    "\n",
    "#### 지도학습 분류기의 일종\n",
    "sum: (value1 * weight1) + (value2 * weight1) \n",
    "\n",
    "\n",
    "<h2>2017 수능 6월 평가원 모의고사 국어영역에 등장한 퍼셉트론</h2>\n",
    "\n",
    "<pre>\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Neuron_Hand-tuned.svg/1179px-Neuron_Hand-tuned.svg.png' width=200>\n",
    "* 이미지 출처 https://ko.wikipedia.org/wiki/%EC%8B%A0%EA%B2%BD_%EC%84%B8%ED%8F%AC\n",
    "\n",
    "인간의 신경 조직을 수학적으로 모델링하여 컴퓨터가 인간처럼 기억․학습․판단할 수 있도록 구현한 것이 인공 신경망 기술이다. 신경 조직의 기본 단위는 뉴런인데, ⓐ 인공 신경망에서는 뉴런의 기능을 수학적으로 모델링한 퍼셉트론을 기본 단위로 사용한다.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Perceptron.svg/1052px-Perceptron.svg.png' width=300>\n",
    "* 이미지 출처 https://en.wikipedia.org/wiki/Perceptron\n",
    "\n",
    "ⓑ퍼셉트론은 입력값들을 받아들이는 여러 개의 ⓒ입력 단자와 이 값을 처리하는 부분, 처리된 값을 내보내는 한 개의 출력 단자로 구성되어 있다. 퍼셉트론은 각각의 입력 단자에 할당된 ⓓ 가중치를 입력값에 곱한 값들을 모두 합하여 가중합을 구한 후, 고정된 ⓔ 임계치보다 가중합이 작으면 0, 그렇지 않으면 1과 같은 방식으로 ⓕ 출력값을 내보낸다.\n",
    "\n",
    "이러한 퍼셉트론은 출력값에 따라 두 가지로만 구분하여 입력값들을 판정할 수 있을 뿐이다. 이에 비해 복잡한 판정을 할 수 있는 인공 신경망은 다수의 퍼셉트론을 여러 계층으로 배열하여 한 계층에서 출력된 신호가 다음 계층에 있는 모든 퍼셉트론의 입력 단자에 입력값으로 입력되는 구조로 이루어진다.\n",
    "\n",
    "이러한 인공 신경망에서 가장 처음에 입력값을 받아들이는 퍼셉트론들을 입력층, 가장 마지막에 있는 퍼셉트론들을 출력층이라고 한다.\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Honeycrisp.jpg/1280px-Honeycrisp.jpg' width=200>\n",
    "* 이미지 출처 https://en.wikipedia.org/wiki/Apple\n",
    "\n",
    "\n",
    "㉠ 어떤 사진 속 물체의 색깔과 형태로부터 그 물체가 사과인지 아닌지를 구별할 수 있도록 인공 신경망을 학습시키는 경우를 생각해 보자. 먼저 학습을 위한 입력값들 즉 학습 데이터를 만들어야 한다. 학습 데이터를 만들기 위해서는 사과 사진을 준비하고 사진에 나타난 특징인 색깔과 형태를 수치화 해야 한다. 이 경우 색깔과 형태라는 두 범주를 수치화하여 하나의 학습 데이터로 묶은 다음, ‘정답’에 해당하는 값과 함께 학습 데이터를 인공 신경망에 제공한다. 이때 같은 범주에 속하는 입력값은 동일한 입력 단자를 통해 들어가도록 해야 한다. 그리고 사과 사진에 대한 학습 데이터를 만들 때에 정답인 ‘사과이다’에 해당하는 값을 ‘1’로 설정하였다면 출력값 ‘0’은 ‘사과가 아니다’를 의미하게 된다.\n",
    "\n",
    "인공 신경망의 작동은 크게 학습 단계와 판정 단계로 나뉜다. 학습 단계는 학습 데이터를 입력층의 입력 단자에 넣어 주고 출력층의 출력값을 구한 후, 이 출력값과 정답에 해당하는 값의 차이가 줄어들도록 가중치를 갱신하는 과정이다. 어떤 학습 데이터가 주어지면 이때의 출력값을 구하고 학습 데이터와 함께 제공된 정답에 해당하는 값에서 출력값을 뺀 값 즉 오차 값을 구한다. 이 오차 값의 일부가 출력층의 출력 단자에서 입력층의 입력 단자 방향으로 되돌아가면서 각 계층의 퍼셉트론별로 출력 신호를 만드는 데 관여한 모든 가중치들에 더해지는 방식으로 가중치들이 갱신된다. 이러한 과정을 다양한 학습 데이터에 대하여 반복하면 출력값들이 각각의 정답 값에 수렴하게 되고 판정 성능이 좋아진다. 오차 값이 0에 근접하게 되거나 가중치의 갱신이 더 이상 이루어지지 않게 되면 학습 단계를 마치고 판정 단계로 전환한다. 이때 판정의 오류를 줄이기 위해서는 학습 단계에서 대상들의 변별적 특징이 잘 반영되어 있는 서로 다른 학습 데이터를 사용하는 것이 좋다.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Learnign Perceptron in Python\n",
    "* 원문 출처 : https://mlwave.com/online-learning-perceptron/\n",
    "\n",
    "* 소스코드 출처\n",
    "\n",
    "    * https://github.com/MLWave/online-learning-perceptron\n",
    "    * https://github.com/MLWave/online-learning-perceptron/blob/master/perceptron.py\n",
    "    * 위 소스코드를 Python3에서 실행되도록 일부 수정하였다.\n",
    "    \n",
    "    \n",
    "파이썬으로 표준 라이브러리를 사용해서 위의 퍼셉트론 알고리즘을 구현했기 때문에 스크립트가 PyPy에서 실행되고 3-4배의 속도향상이 있다. 여기에 사용된 알고리즘은 Kaggle 포럼에서 처음 발견 된 tinrtgu의 온라인 로지스틱 회귀 스크립트에서 큰 영감을 얻었다고 한다.\n",
    "\n",
    "다음 경진대회에서 Vowpal Wabbit을 통한 해시트릭을 사용하였고 코드가 공개되어 있다.\n",
    "\n",
    "Display Advertising Challenge - Kaggle, Beat the benchmark with less then 200MB of memory.\n",
    "코드 : https://kaggle2.blob.core.windows.net/forum-message-attachments/53646/1539/fast_solution.py\n",
    "\n",
    "\n",
    "### 온라인 학습\n",
    "online learning : https://en.wikipedia.org/wiki/Online_machine_learning\n",
    "퍼셉트론은 온라인 학습이 가능하다(한 번에 하나씩 샘플을 통해 학습). 메모리에 전체 데이터 세트가 필요하지 않으므로(out-of-core) 더 큰 데이터 세트에 유용하다. 여기에서는 Vowpal Wabbit에서 온라인 학습 코드를 가져왔다.\n",
    "\n",
    "* Vowpal Wabbit (Fast Learning)\n",
    "* Hashing Representations\n",
    "\n",
    "\n",
    "### 해싱 트릭\n",
    "벡터화 해싱 트릭은 Vowpal Wabbit(John Langford)에서 시작되었다. 이 트릭은 퍼셉트론으로 들어오는 연결 수를 고정 된 크기로 설정한다. 고정 된 크기보다 낮은 숫자로 모든 원시 피처를 해싱한다. Vowpal Wabbit은 모든 데이터를 메모리로 읽어들이지 않고 모델을 훈련 시킬 수 있는 빠른 머신러닝 라이브러리다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'movie', 'sucks']\n",
      "[(11, 1), (90, 1), (1010, 1)]\n"
     ]
    }
   ],
   "source": [
    "sample = \"This movie sucks\"\n",
    "fixed_size = 1024\n",
    "\n",
    "print(sample.split())\n",
    "\n",
    "features = [(hash(f)%fixed_size,1) for f in sample.split()]\n",
    "\n",
    "# list of tuples in form (feature_index,feature_value)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로그레시브 검증 손실\n",
    "한 번에 하나씩 표본을 학습하면 점진적으로 train loss가 된다. 모델이 타겟을 보지않고 첫 샘플을 보고 예측을 한다. 그런 다음 예측을 대상 레이블과 비교하여 오류율을 계산 한다. 오류율이 낮으면 좋은 모델에 가깝다.\n",
    "\n",
    "### Multiple passes\n",
    "Vowpal Wabbit을 사용하면 학습률이 떨어지는 데이터 집합을 여러 번 통과시킬 수 있다.\n",
    "\n",
    "오류율이 낮아지면 데이터 세트를 여러 번 실행할 수도 있다. 트레이닝 데이터가 선형 적으로 분리 가능한 경우, 퍼셉트론은 트레이닝 세트에서 오차가 0으로 수렴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33554432"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# opts[\"D\"] 여기에 있는 코드에서는 고정 값으로 다음의 값을 사용한다.\n",
    "2 ** 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 코드에서는 pandas, numpy, scipy같은 도구를 사용하지 않고 파이썬에 내장 된 기능만을 사용해 학습하도록 한다.\n",
    "* 원래 코드는 파이썬2로 되어 있지만, 파이썬3에서 돌아가도록 코드의 일부를 수정하였다.\n",
    "\n",
    "* 소스코드 출처 https://github.com/MLWave/online-learning-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 정규표현식을 사용해 텍스트 데이터를 정제하기 위해\n",
    "import random # 랜덤 숫자를 생성하기 위해\n",
    "from math import exp, log # 지수함수와 로그함수를 사용하기 위해\n",
    "from datetime import datetime # 시간을 계산하기 위해\n",
    "from operator import itemgetter # 키가 아닌 값으로 max, min 값을 구할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규표현식만을 사용해서 data clearning할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    \"\"\"\n",
    "        Returns a cleaned, lowercased string\n",
    "        \n",
    "    \"\"\"\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset,opts):\n",
    "    \"\"\"\n",
    "    Running through data in an online manner\n",
    "    Parses a tsv file for this competition \n",
    "    and yields label, identifier and features\n",
    "    output:\n",
    "            label: int, The label / target (set to \"1\" if test set)\n",
    "            id: string, the sample identifier\n",
    "            features: list of tuples, \n",
    "                in the form [(hashed_feature_index,feature_value)]\n",
    "\n",
    "    온라인 학습 방법을 통해 데이터를 실행한다.\n",
    "    tsv파일을 통해 레이블, identifier, 피처(특성)를 파싱한다.\n",
    "    결과물:\n",
    "        label : int, 레이블 / 대상 (테스트 집합 인 경우 \"1\"로 설정)\n",
    "        id : 문자열, 샘플 식별자\n",
    "        features : [(hashed_feature_index, feature_value)] \n",
    "                형식의 튜플 목록\n",
    "    \"\"\"\n",
    "    for e, line in enumerate(open(loc_dataset,\"rb\")):\n",
    "        if e > 0:\n",
    "            r = line.decode('utf-8').strip().split(\"\\t\")\n",
    "            id = r[0]\n",
    "\n",
    "            if opts[\"clean\"]:\n",
    "                try:\n",
    "                    r[2] = clean(r[2]) # train data 일때 review\n",
    "                except:\n",
    "                    r[1] = clean(r[1]) # test data일 때 \n",
    "\n",
    "            # opts[\"D\"] = 2 ** 25 = 33554432\n",
    "            # Vowpal Wabbit의 해싱트릭을 사용한다.\n",
    "            # 해싱트릭은 큰 규모의 feature공간을 \n",
    "            # 고정크기의 표현을 사용해 저장할 수 있게 한다.\n",
    "            if len(r) == 3: # train set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else: #test set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[1].split()]\n",
    "                label = 1\n",
    "\n",
    "            # bigram을 사용하면 해당 피처[i]와 다음피처[i+1]를 함께 해싱한다.\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append(\n",
    "                        (hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(features,weights):\n",
    "    \"\"\"\n",
    "    Calculate dot product from features and weights\n",
    "    input:\n",
    "            features: A list of tuples [(feature_index,feature_value)]\n",
    "            weights: the hashing trick weights filter, \n",
    "            note: length is max(feature_index)\n",
    "    output:\n",
    "            dotp: the dot product\n",
    "    피처(특성)과 가중치로부터 내적을 구한다.\n",
    "    \"\"\"\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "    return dotp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    # 가중치 초기화\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    # Running training passes\n",
    "    # 학습 실행\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( \\\n",
    "            get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "            # 퍼셉트론은 지도학습 분류기의 일종이다. \n",
    "            # 이전 값에 대한 학습으로 예측을 한다. \n",
    "            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 \n",
    "            # 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "\n",
    "            # 다음 perceptron은 샘플의 레이블을 본다. \n",
    "            # 실제 레이블 데이터에서 위 퍼셉트론으로 구한 dp값을 빼준다.\n",
    "            # 예측이 정확하다면, error 값은 \"0\"이며, 가중치만 남겨 둔다. \n",
    "            # 예측이 틀린 경우 error 값은 \"1\" 또는 \"-1\"이고 다음과 같이 가중치를 업데이트 한다.\n",
    "            # weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp \n",
    "\n",
    "            # 예측이 틀린 경우 퍼셉트론은 다음과 같이 가중치를 업데이트한다.\n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        #Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "\n",
    "        #Oh heh, we have overfit :)\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset,weights,opts):\n",
    "    \"\"\"\n",
    "        output:\n",
    "                preds: list, a list with\n",
    "                [id,prediction,dotproduct,0-1normalized dotproduct]\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    preds = [] # 예측한 값들을 넣어준다.\n",
    "    error_counter = 0 # \n",
    "    for e, (label, id, features) in enumerate( \\ # test데이터는 label이 없으므로 1로 초기화\n",
    "        get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "        dotp = dot_product(features, weights)\n",
    "        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append( [id, 1, dotp ] )\n",
    "        else:\n",
    "            preds.append( [id, 0, dotp ] )\n",
    "\n",
    "        # get_data_tsv에서 테스트 데이터의 레이블을 1로 초기화 해주었음\n",
    "        if label - dp != 0:\n",
    "            error_counter += 1\n",
    "\n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "        error_counter,\n",
    "        round(1 - error_counter /float(e+1),5),\n",
    "        e+1,\n",
    "        datetime.now()-start))\n",
    "\n",
    "    # normalizing dotproducts between 0 and 1 \n",
    "    # 내적을 구해 0과 1로 일반화 한다.\n",
    "    # TODO: proper probability (bounded sigmoid?), \n",
    "    # online normalization\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    for p in preds:\n",
    "        # appending normalized to predictions\n",
    "        # 정규화 된 값을 마지막에 추가해 준다.\n",
    "        # (피처와 가중치에 대한 내적값 - 최소 내적값) / 최대 내적값 - 최소 내적값\n",
    "        # 이 값이 캐글에서 0.95의 AUC를 얻을 수 있는 값이다.\n",
    "        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) \n",
    "\n",
    "    #Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5627\t\t0.77492\t\t25000\t\t0:00:29.194759\n",
      "2\t\t3105\t\t0.8758\t\t25000\t\t0:01:01.437466\n",
      "3\t\t2263\t\t0.90948\t\t25000\t\t0:01:44.707877\n",
      "4\t\t1644\t\t0.93424\t\t25000\t\t0:02:16.562501\n",
      "5\t\t1302\t\t0.94792\t\t25000\t\t0:02:56.043091\n",
      "6\t\t1007\t\t0.95972\t\t25000\t\t0:03:34.317175\n",
      "7\t\t806\t\t0.96776\t\t25000\t\t0:04:11.278140\n",
      "8\t\t693\t\t0.97228\t\t25000\t\t0:04:47.200586\n",
      "9\t\t522\t\t0.97912\t\t25000\t\t0:05:21.177859\n",
      "10\t\t446\t\t0.98216\t\t25000\t\t0:05:58.736324\n",
      "11\t\t405\t\t0.9838\t\t25000\t\t0:06:39.198686\n",
      "12\t\t366\t\t0.98536\t\t25000\t\t0:07:19.365113\n",
      "13\t\t228\t\t0.99088\t\t25000\t\t0:07:58.637082\n",
      "14\t\t257\t\t0.98972\t\t25000\t\t0:08:35.715865\n",
      "15\t\t240\t\t0.9904\t\t25000\t\t0:09:11.469435\n",
      "16\t\t151\t\t0.99396\t\t25000\t\t0:09:51.090158\n",
      "17\t\t155\t\t0.9938\t\t25000\t\t0:10:25.319290\n",
      "18\t\t135\t\t0.9946\t\t25000\t\t0:10:57.152690\n",
      "19\t\t133\t\t0.99468\t\t25000\t\t0:11:29.626189\n",
      "20\t\t119\t\t0.99524\t\t25000\t\t0:12:08.160479\n",
      "21\t\t130\t\t0.9948\t\t25000\t\t0:12:40.789174\n",
      "22\t\t63\t\t0.99748\t\t25000\t\t0:13:17.177658\n",
      "23\t\t126\t\t0.99496\t\t25000\t\t0:13:53.580324\n",
      "24\t\t91\t\t0.99636\t\t25000\t\t0:14:29.030079\n",
      "25\t\t86\t\t0.99656\t\t25000\t\t0:14:54.384208\n",
      "26\t\t24\t\t0.99904\t\t25000\t\t0:15:31.666448\n",
      "27\t\t81\t\t0.99676\t\t25000\t\t0:16:11.425563\n",
      "28\t\t54\t\t0.99784\t\t25000\t\t0:16:44.564331\n",
      "29\t\t44\t\t0.99824\t\t25000\t\t0:17:16.234985\n",
      "30\t\t19\t\t0.99924\t\t25000\t\t0:17:42.730480\n",
      "31\t\t32\t\t0.99872\t\t25000\t\t0:18:07.375585\n",
      "32\t\t32\t\t0.99872\t\t25000\t\t0:18:37.034283\n",
      "33\t\t44\t\t0.99824\t\t25000\t\t0:19:00.476198\n",
      "34\t\t38\t\t0.99848\t\t25000\t\t0:19:24.139928\n",
      "35\t\t32\t\t0.99872\t\t25000\t\t0:19:45.970558\n",
      "36\t\t15\t\t0.9994\t\t25000\t\t0:20:08.063483\n",
      "37\t\t59\t\t0.99764\t\t25000\t\t0:20:33.215235\n",
      "38\t\t27\t\t0.99892\t\t25000\t\t0:20:56.590734\n",
      "39\t\t25\t\t0.999\t\t25000\t\t0:21:20.567623\n",
      "40\t\t23\t\t0.99908\t\t25000\t\t0:21:52.290802\n",
      "41\t\t15\t\t0.9994\t\t25000\t\t0:22:15.330198\n",
      "42\t\t16\t\t0.99936\t\t25000\t\t0:22:39.167464\n",
      "43\t\t6\t\t0.99976\t\t25000\t\t0:23:03.229126\n",
      "44\t\t2\t\t0.99992\t\t25000\t\t0:23:32.691350\n",
      "45\t\t0\t\t1.0\t\t25000\t\t0:23:55.212137\n",
      "0 errors found during training, halting\n",
      "Wall time: 23min 55s\n"
     ]
    }
   ],
   "source": [
    "#Setting options\n",
    "opts = {}\n",
    "opts[\"D\"] = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80 # Maximum number of passes to run before halting 몇번의  forloop를 돌 것인가\n",
    "opts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\n",
    "opts[\"random_init\"] = False # set random weights, else set all 0\n",
    "opts[\"clean\"] = True # clean the text a little\n",
    "opts[\"2grams\"] = True # add 2grams\n",
    "\n",
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"../input/kaggle_data/Bag_of_Words_Meets_Bags_Of_Popcorn/labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing online\n",
      "Errors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "12191\t\t0.51236\t\t25000\t\t0:00:22.203662\n",
      "Done testing in 0:00:22.220619\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "# testing and saving predictions into preds\n",
    "%time preds = test_tron(\"../input/kaggle_data/Bag_of_Words_Meets_Bags_Of_Popcorn/testData.tsv\",weights,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"12311_10\"', 1, 82.13794089635356, 0.6128650904033375],\n",
       " ['\"8348_2\"', 0, -106.74466580623155, 0.4233657858136293],\n",
       " ['\"5828_4\"', 1, 9.080228065335247, 0.5395688456189145],\n",
       " ['\"7186_2\"', 1, 5.8224363167035165, 0.5363004172461745],\n",
       " ['\"12128_7\"', 1, 41.311571961372735, 0.5719054242002775],\n",
       " ['\"2913_8\"', 1, 83.24697638524935, 0.6139777468706531],\n",
       " ['\"4396_1\"', 0, -49.35207925586808, 0.48094575799721767],\n",
       " ['\"395_2\"', 0, 0.4158883083359156, 0.5308762169680104],\n",
       " ['\"10616_1\"', 0, -98.01101133117618, 0.43212795549374067],\n",
       " ['\"9074_9\"', 0, -27.656572504341867, 0.5027121001390813]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing kaggle submission\n",
    "# 캐글 점수 제출을 위한 서브미션 파일을 작성한다.\n",
    "with open(\"../output/submit_perceptron.csv\",\"wb\") as outfile:\n",
    "    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n",
    "    for p in sorted(preds):\n",
    "        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>82.137941</td>\n",
       "      <td>0.612865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-106.744666</td>\n",
       "      <td>0.423366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "      <td>9.080228</td>\n",
       "      <td>0.539569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>1</td>\n",
       "      <td>5.822436</td>\n",
       "      <td>0.536300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>41.311572</td>\n",
       "      <td>0.571905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1           2         3\n",
       "0  \"12311_10\"  1   82.137941  0.612865\n",
       "1    \"8348_2\"  0 -106.744666  0.423366\n",
       "2    \"5828_4\"  1    9.080228  0.539569\n",
       "3    \"7186_2\"  1    5.822436  0.536300\n",
       "4   \"12128_7\"  1   41.311572  0.571905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐글에 제출할 때 바이너리 타입으로 제출하라고 되어 있는데 여기에서는 바이너리로 변환하지 않은 채 제출을 했다.\n",
    "# 그런데 캐글에서 점수가 평가되고 심지어 높은 점수로! \n",
    "# 그래서 다시 바이너리 형태의 예측값을 제출했더니 점수가 낮아졌다. \n",
    "# 바이너리로 제출한 스코어가 훨씬 낮은 0.89132 가 나왔지만 튜토리얼에 있는 방법을 사용했을 때보다 훨씬 높은 스코어다.\n",
    "# 머신러닝 패키지를 사용하지 않고 파이썬의 내장 기능을 통해서 이런 점수가 나올 수 있다는 것에 놀랐다.\n",
    "import pandas as pd\n",
    "\n",
    "presult = pd.DataFrame(preds)\n",
    "presult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12809\n",
       "0    12191\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = presult[1].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상위 벤치 마크\n",
    "포럼에서 현재 가장 좋은 벤치 마크 는 Abhishek 의 로지스틱 회귀 스크립트다. 리더 보드에서 0.95 AUC 를 얻기 위해 학습과 테스트 세트의 메모리 안에서 tfidf-fit_transform을 사용한다. 여기에서는 이 변환을 건너 뛰고 온라인 해시 벡터 라이저를 사용한다.\n",
    "\n",
    "Abhishek의 스크립트처럼 기능에서 2-gram(좋지 않은등)을 생성한다. 2-gram을 단순히 해쉬하고 샘플 벡터에 추가한다.\n",
    "\n",
    "또, 문자를 소문자로 바꾸고 영숫자가 아닌 것을 제거함으로써 텍스트를 조금 더 빠르게 정제한다.\n",
    "\n",
    "### 예측\n",
    "AUC를 최적화하기 위해 1또는 0예측만 제출하지 않는다. 이것은 약 0.88의 AUC를 줄 것이다. 여기에서는 0과 1 사이에서 정규화된 dotproduct를 제출한다.\n",
    "\n",
    "이 스크립트는 Abhishek의 솔루션 0.952 점수와 비교해 본다. 하지만 이 코드는 단지 몇 MB의 메모리를 필요로하며, tfidf 변환을 수행하지 않고 단지 2분 만에 0의 학습오류에 수렴한다다.\n",
    "\n",
    "텍스트 정제와 2-gram이 없으면 스크립트는 60초 이내에 실행되고 0.93의 점수를 산출한다.\n",
    "\n",
    "### 결론\n",
    "절대적인 지식은 없다. 모든 것은 확률에 의해서만 이루어진다 - Gödel (1961)\n",
    "\n",
    "0-1 임계 값 활성화가 적용된 매우 기본적인 퍼셉트론은 NLP 경진대회에서 잘 동작한다. 여기에서는 1957 알고리즘을 전혀 변경하지 않았다. 해싱 트릭을 없애고 비슷하거나 약간 더 좋은 점수를 받을 수 있다.\n",
    "\n",
    "이 스크립트는 확률을 출력 할 수 없다. dotproduct에 bounded sigmoid를 사용하여 출력의 온라인 정규화 형태를 얻거나 tinrtgu의 (Vowpal Wabbit)스크립트를 더 보완해 볼 수 있을 것이다.\n",
    "\n",
    "단일 노드 단일 레이어 퍼셉트론은 비선형 함수를 모델링 할 수 없으므로 더 나은 NLP 출력을 얻으려면 FFN(feedforward nets), recurrent nets, self-organizing maps, MLP(Multi-layer Perceptrons), word2vec 및 extreme learning machine (백프로파게이션이 없는 fast ffnets)을 봐야할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
