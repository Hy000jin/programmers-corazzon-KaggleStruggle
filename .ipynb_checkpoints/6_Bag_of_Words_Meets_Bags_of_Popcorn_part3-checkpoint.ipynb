{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로그래머스 강의\n",
    "github - [corazzon-github](https://github.com/corazzon/KaggleStruggle/)\n",
    "## NLP method\n",
    "1. **word2vec을 통한 모델 생성**하여 모델로 벡터의 평균을 구하여, 랜덤포레스트를 사용하여 예측.(part2에서 시행)\n",
    "\n",
    "2. **Vector-quantization(벡터 양자화)**로 단어의 중심을 찾음으로써 클러스터링을 하고 랜덤포레스트로 예측 (part3에서 시행)\n",
    "\n",
    "\n",
    "## K-means with NLP\n",
    "벡터 양자화를 위하여 k-means와 같은 클러스터링 알고리즘을 사용한다. \n",
    "\n",
    "* K-means\n",
    "    * word2vec은 의미가 관련있는 단어들의 클러스터를 생성하기 때문에 클러스터 내의 단어 유사성을 이용하는 것이다. \n",
    "    * 이런식으로 벡터를 그룹화 하는 것을 'vector quantization(벡터 양자화)'라고 한다.\n",
    "    * 이를 위해서는 K-means와 같은 클러스터리 알고리즘을 사용하여 클러스터라는 단어의 중심을 찾아야 한다.\n",
    "    * 비지도학습인 K-means를 통해 클러스터링을 하고 지도학습인 랜덤포레스트로 리뷰가 추천인지 아닌지를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyooo\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2840906df28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load('300features_40minwords_10text') # 300 feature와 400min word, 10개의 text window\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyooo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 숫자로 단어를 표현\n",
    "# Word2Vec 모델은 어휘의 각 단어에 대한 feature 벡터로 구성되며 \n",
    "# 'syn0'이라는 넘파이 배열로 저장된다.\n",
    "# syn0의 행 수는 모델 어휘의 단어 수\n",
    "# 컬럼 수는 2 부에서 설정 한 피처 벡터의 크기\n",
    "type(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyooo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11986, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# syn0의 행 수는 모델 어휘의 단어 수\n",
    "# 열 수는 2부에서 설정한 특징 벡터의 크기\n",
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 단어 벡터 접근\n",
    "model.wv['flower'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01080903, -0.0272022 ,  0.0031521 , -0.01389461, -0.0097832 ,\n",
       "        0.09947107, -0.03870872, -0.01805819, -0.11280139,  0.03873673],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['flower'][:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means (K-평균)클러스터링으로 데이터 묶기\n",
    "* K-평균 알고리즘 - 위키백과, 우리 모두의 백과사전\n",
    "* 클러스터링은 비지도 학습 기법\n",
    "* 클러스터링은 유사성 등 개념에 기초해 몇몇 그룹으로 분류하는 기법\n",
    "* 클러스터링의 목적은 샘플(실수로 구성된 n차원의 벡터)을 내부적으로는 비슷하지만 외부적으로 공통 분모가 없는 여러 그룹으로 묶는 것\n",
    "* 특정 차원의 범위가 다른 차원과 차이가 크면 클러스터링 하기 전에 스케일을 조정해야 한다.\n",
    "    1. 최초 센트로이드(centroid)(중심점)로 k개의 벡터를 무작위로 선정한다.\n",
    "    2. 각 샘플을 그 위치에서 가장 가까운 센트로이드에 할당한다.\n",
    "    3. 센트로이드의 위치를 재계산한다.\n",
    "    4. 센트로이드가 더 이상 움직이지 않을 때까지 2와 3을 반복한다.\n",
    "    \n",
    "참고 : [책] 모두의 데이터 과학(with 파이썬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyooo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 클러스터의 크리 \"k\"를 어휘 크기의 1/5이나 평균 5단어로 설정한다.\n",
    "word_vectors = model.wv.syn0 # 어휘의 featrue vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08088318, -0.0112606 ,  0.09067289, ...,  0.06511134,\n",
       "        -0.11464473,  0.07220144],\n",
       "       [-0.04454662, -0.00670921, -0.09436098, ...,  0.00109811,\n",
       "        -0.12423973,  0.0094285 ],\n",
       "       [-0.04313657,  0.00381213,  0.03416809, ..., -0.01421188,\n",
       "        -0.08295558,  0.05679886],\n",
       "       ...,\n",
       "       [-0.08443179, -0.15630306,  0.02527716, ..., -0.04110841,\n",
       "         0.05238528, -0.08074894],\n",
       "       [-0.0552061 , -0.02151591, -0.05291229, ..., -0.09050909,\n",
       "        -0.02749471,  0.0310266 ],\n",
       "       [-0.06902225,  0.00431364, -0.00725025, ..., -0.14348069,\n",
       "         0.05668186,  0.03577482]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyooo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:257: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return distances if squared else np.sqrt(distances, out=distances)\n",
      "C:\\Users\\hyooo\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:400: RuntimeWarning: invalid value encountered in sqrt\n",
      "  max_iter=max_iter, verbose=verbose)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  2179.213337659836 seconds.\n"
     ]
    }
   ],
   "source": [
    "num_clusters = word_vectors.shape[0] #5\n",
    "num_clusters = int(num_clusters)\n",
    "\n",
    "\n",
    "# 단어 벡터에서 k-means를 실행하고 일부 클러스터를 찍어본다.\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# K means를 정의하고 학습시킨다. \n",
    "\n",
    "\n",
    "kmeans_clustering = KMeans(n_clusters = num_clusters)\n",
    "idx = kmeans_clustering.fit_predict(word_vectors)\n",
    "\n",
    "# 끝난시간에서 시작시간을 빼서 걸린 시간을 구한다.\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['gabriel']\n",
      "\n",
      "Cluster 1\n",
      "['rehabilit']\n",
      "\n",
      "Cluster 2\n",
      "['brainless']\n",
      "\n",
      "Cluster 3\n",
      "['wisdom']\n",
      "\n",
      "Cluster 4\n",
      "['truck']\n",
      "\n",
      "Cluster 5\n",
      "['poland']\n",
      "\n",
      "Cluster 6\n",
      "['rous']\n",
      "\n",
      "Cluster 7\n",
      "['riff']\n",
      "\n",
      "Cluster 8\n",
      "['yellow']\n",
      "\n",
      "Cluster 9\n",
      "['unflinch']\n"
     ]
    }
   ],
   "source": [
    "# 각 어휘 단어를 클러스터 번호에 매핑되게 word/Index 사전을 만든다.\n",
    "idx = list(idx)\n",
    "names = model.wv.index2word\n",
    "word_centroid_map = {names[i]: idx[i] for i in range(len(names))}\n",
    "#     word_centroid_map = dict(zip( model.wv.index2word, idx ))\n",
    "\n",
    "# 첫번째 클러스터의 처음 10개를 출력\n",
    "for cluster in range(0,10):\n",
    "    # 클러스터 번호를 출력\n",
    "    print(\"\\nCluster {}\".format(cluster))\n",
    "    \n",
    "    # 클러스터번호와 클러스터에 있는 단어를 찍는다.\n",
    "    words = []\n",
    "    for i in range(0,len(list(word_centroid_map.values()))):\n",
    "        if( list(word_centroid_map.values())[i] == cluster ):\n",
    "            words.append(list(word_centroid_map.keys())[i])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/labeledTrainData.tsv', \n",
    "                    header=0, delimiter='\\t', quoting=3)\n",
    "\n",
    "test = pd.read_csv('../input/testData.tsv', \n",
    "                   header=0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
    "# 학습 리뷰를 정제한다.\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append(\n",
    "        KaggleWord2VecUtility.review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "    \n",
    "\n",
    "# 테스트 리뷰를 정제한다.\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append(\n",
    "        KaggleWord2VecUtility.review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bags of centroids 생성\n",
    "# 속도를 위해 centroid 학습 세트 bag을 미리 할당 한다.\n",
    "train_centroids = np.zeros((train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "train_centroids[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
